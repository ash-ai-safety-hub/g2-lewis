{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_P_matrix(p):\n",
    "    \"\"\"\n",
    "    P_{kij} = P(Agent 0 observes i, Agent 1 observes j | Currently in state k)\n",
    "    \"\"\"\n",
    "    p1_matrix = torch.tensor([\n",
    "        [1-p,p,0,0],\n",
    "        [p,1-p,0,0],\n",
    "        [0,0,1-p,p],\n",
    "        [0,0,p,1-p]\n",
    "    ], dtype=torch.float32).unsqueeze(-1)\n",
    "    p2_matrix = torch.tensor([\n",
    "        [1-p,0,p,0],\n",
    "        [0,1-p,0,p],\n",
    "        [p,0,1-p,0],\n",
    "        [0,p,0,1-p]\n",
    "    ], dtype=torch.float32).unsqueeze(-1)\n",
    "    return torch.matmul(p1_matrix,p2_matrix.mT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Q_matrix(policy_1, policy_2):\n",
    "    \"\"\"\n",
    "    Q_{lij} = Pr(Going to state l | Agent 0 sees i, Agent 1 sees j)\n",
    "    \"\"\"\n",
    "    p1 = policy_1.unsqueeze(-1)\n",
    "    p2 = policy_2.unsqueeze(-1)\n",
    "    return torch.stack(((1-p1)@(1-p2).T, (1-p1)@p2.T, p1@(1-p2).T, p1@p2.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "tensor([[0.4477, 0.4513, 0.0503, 0.0507],\n",
      "        [0.3188, 0.4822, 0.0792, 0.1198],\n",
      "        [0.2111, 0.4879, 0.0909, 0.2101],\n",
      "        [0.1214, 0.4796, 0.0806, 0.3184]])\n"
     ]
    }
   ],
   "source": [
    "p_i = torch.tensor([0.1, 0.2, 0.3, 0.4]).float()\n",
    "p_j = torch.tensor([0.5, 0.6, 0.7, 0.8]).float()\n",
    "p = 0.01\n",
    "\n",
    "P = generate_P_matrix(p)\n",
    "Q = generate_Q_matrix(p_i, p_j)\n",
    "\n",
    "print(P.dtype)\n",
    "print(Q.dtype)\n",
    "PQ = torch.einsum(\"kij, lij -> kl\", [P, Q])\n",
    "#PQ = torch.tensordot(P, Q)\n",
    "print(PQ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyIPD:\n",
    "    def __init__(self, game, p_i, p_j, p, gamma):\n",
    "        \"\"\"\n",
    "        Note: self.game should be 4x2\n",
    "        \"\"\"\n",
    "        self.game = game.float()\n",
    "        self.p_i = torch.nn.Parameter(p_i.float(), requires_grad=True)\n",
    "        self.p_j = torch.nn.Parameter(p_j.float(), requires_grad=True)\n",
    "        self.policies = (self.p_i, self.p_j)\n",
    "        self.p = p\n",
    "        self.gamma = gamma\n",
    "        self.P = generate_P_matrix(self.p)\n",
    "        self.Q = generate_Q_matrix(self.p_i, self.p_j)\n",
    "        self.values_0, self.values_1 = self.find_values(self.P, self.Q)\n",
    "\n",
    "\n",
    "    def find_values(self, P, Q):\n",
    "        \n",
    "        I = torch.eye(4)  # Identity matrix of size 4x4\n",
    "            \n",
    "        # sum over ij of P_kij * Q_lij\n",
    "\n",
    "        PQ = torch.einsum(\"kij, lij -> kl\", P, Q)\n",
    "#        self.subtracted_matrix = I - self.gamma * torch.matmul(self.P, self.Q)\n",
    "        self.subtracted_matrix = I - self.gamma * PQ\n",
    "        \n",
    "        inverse_matrix = torch.linalg.solve(self.subtracted_matrix, torch.eye(4))\n",
    "        values = torch.matmul(inverse_matrix, self.game.T)\n",
    "\n",
    "        return values.T\n",
    "\n",
    "\n",
    "    def optimize(self, num_iterations, policy_index, learning_rate=0.05):\n",
    "        #  logit_p_i = torch.log(self.p_i / (1 - self.p_i)).clone().detach().requires_grad_(True)  # Logit transformation\n",
    "        policy = self.policies[policy_index]\n",
    "        rival_policy = self.policies[1-policy_index]\n",
    "        rival_policy.requires_grad_(False)\n",
    "\n",
    "        logit_policy = torch.logit(policy).clone().detach().requires_grad_(True)  # Logit transformation\n",
    "\n",
    "        optimizer = torch.optim.Adam([logit_policy], lr=learning_rate)\n",
    "\n",
    "        storage = {}\n",
    "        storage[\"policy\"] = []\n",
    "        storage[\"values\"] = []\n",
    "        storage[\"total_value\"] = []\n",
    "        storage[\"loss\"] = []\n",
    "\n",
    "        for i in range(num_iterations):\n",
    "            #print(f\"\\n Run {i}\")\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            policy = torch.sigmoid(logit_policy)\n",
    "\n",
    "            if policy_index == 0:\n",
    "                self.Q = generate_Q_matrix(policy, rival_policy)\n",
    "            else:\n",
    "                self.Q = generate_Q_matrix(rival_policy, policy)\n",
    "            \n",
    "            values = self.find_values(self.P, self.Q)\n",
    "\n",
    "            loss = -values[policy_index].sum()   # We want to maximize self.values_0, so we negate it for minimization\n",
    "            #  loss.backward(retain_graph=True)\n",
    "            loss.backward()\n",
    "\n",
    "            #print(\"p_i values:\", self.p_i)\n",
    "            #print(\"value for agent i:\", self.values_0)\n",
    "            #print(\"total value for agent i:\", self.values_0.sum())\n",
    "            #print(\"loss:\", loss)  # Check the value of the loss\n",
    "            storage[\"policy\"].append(policy)\n",
    "            storage[\"values\"].append(values[policy_index])\n",
    "            storage[\"total_value\"].append(values[policy_index].sum())\n",
    "            storage[\"loss\"].append(loss.item())\n",
    "\n",
    "            optimizer.step()\n",
    "        \n",
    "        \n",
    "        return storage\n",
    "\n",
    "#            with torch.no_grad():  # We don't want these operations to be tracked in the computational graph\n",
    "#                eps = 1e-7\n",
    "#                logit_p_i = torch.log((self.p_i + eps) / (1 - self.p_i + eps)).clone().detach().requires_grad_(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prisoners_dilemma = torch.tensor([[3, 0, 4, 1],\n",
    "                                  [3, 4, 0, 1]])\n",
    "gamma = 0.999\n",
    "\n",
    "game_obj = NoisyIPD(game = prisoners_dilemma,\n",
    "                        p_i = torch.tensor([0.1, 0.2, 0.3, 0.4]).float(),\n",
    "                        p_j = torch.tensor([0.5, 0.6, 0.7, 0.8]).float(),\n",
    "                        p = p,\n",
    "                        gamma = gamma)\n",
    "\n",
    "#storage_vals = game_obj.optimize_pi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = game_obj.optimize(policy_index=1, num_iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "storage['loss']\n",
    "plt.plot(storage['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.5000, 0.6000, 0.7000, 0.8000], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.5125, 0.6119, 0.7104, 0.8079], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.5250, 0.6237, 0.7206, 0.8155], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.5374, 0.6354, 0.7305, 0.8229], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.5497, 0.6469, 0.7401, 0.8301], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.5619, 0.6583, 0.7495, 0.8370], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.5740, 0.6694, 0.7586, 0.8437], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.5859, 0.6804, 0.7674, 0.8501], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.5977, 0.6912, 0.7759, 0.8564], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.6092, 0.7018, 0.7840, 0.8624], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.6205, 0.7121, 0.7919, 0.8681], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.6316, 0.7223, 0.7995, 0.8737], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.6424, 0.7322, 0.8067, 0.8790], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.6529, 0.7418, 0.8136, 0.8841], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.6631, 0.7512, 0.8202, 0.8890], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.6730, 0.7604, 0.8265, 0.8937], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.6826, 0.7692, 0.8325, 0.8981], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.6919, 0.7779, 0.8382, 0.9024], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7008, 0.7862, 0.8437, 0.9065], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7094, 0.7943, 0.8488, 0.9104], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7177, 0.8021, 0.8537, 0.9142], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7257, 0.8096, 0.8583, 0.9177], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7333, 0.8169, 0.8627, 0.9211], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7406, 0.8239, 0.8669, 0.9244], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7475, 0.8307, 0.8708, 0.9274], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7542, 0.8371, 0.8745, 0.9304], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7605, 0.8434, 0.8780, 0.9332], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7666, 0.8493, 0.8813, 0.9358], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7724, 0.8551, 0.8844, 0.9383], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7779, 0.8605, 0.8874, 0.9407], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7831, 0.8658, 0.8902, 0.9430], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7881, 0.8708, 0.8928, 0.9452], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7928, 0.8756, 0.8953, 0.9472], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7974, 0.8802, 0.8976, 0.9492], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8016, 0.8846, 0.8998, 0.9510], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8057, 0.8888, 0.9019, 0.9528], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8096, 0.8928, 0.9039, 0.9545], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8132, 0.8966, 0.9058, 0.9561], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8167, 0.9002, 0.9076, 0.9576], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8201, 0.9037, 0.9092, 0.9590], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8232, 0.9070, 0.9108, 0.9604], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8262, 0.9102, 0.9123, 0.9617], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8291, 0.9132, 0.9137, 0.9630], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8318, 0.9161, 0.9151, 0.9641], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8343, 0.9188, 0.9164, 0.9653], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8368, 0.9214, 0.9176, 0.9663], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8391, 0.9239, 0.9187, 0.9674], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8414, 0.9263, 0.9198, 0.9683], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8435, 0.9286, 0.9209, 0.9693], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8455, 0.9307, 0.9219, 0.9702], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8474, 0.9328, 0.9228, 0.9710], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8493, 0.9348, 0.9237, 0.9718], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8510, 0.9366, 0.9246, 0.9726], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8527, 0.9385, 0.9254, 0.9733], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8543, 0.9402, 0.9262, 0.9740], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8559, 0.9418, 0.9269, 0.9747], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8573, 0.9434, 0.9276, 0.9754], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8587, 0.9449, 0.9283, 0.9760], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8601, 0.9464, 0.9290, 0.9766], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8614, 0.9477, 0.9296, 0.9771], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8626, 0.9491, 0.9302, 0.9777], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8638, 0.9503, 0.9308, 0.9782], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8650, 0.9516, 0.9313, 0.9787], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8661, 0.9527, 0.9319, 0.9792], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8671, 0.9539, 0.9324, 0.9797], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8682, 0.9549, 0.9329, 0.9801], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8691, 0.9560, 0.9333, 0.9806], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8701, 0.9570, 0.9338, 0.9810], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8710, 0.9579, 0.9342, 0.9814], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8719, 0.9589, 0.9347, 0.9818], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8727, 0.9597, 0.9351, 0.9821], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8736, 0.9606, 0.9355, 0.9825], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8744, 0.9614, 0.9359, 0.9828], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8751, 0.9622, 0.9362, 0.9832], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8759, 0.9630, 0.9366, 0.9835], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8766, 0.9637, 0.9370, 0.9838], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8773, 0.9645, 0.9373, 0.9841], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8780, 0.9651, 0.9376, 0.9844], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8786, 0.9658, 0.9379, 0.9847], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8793, 0.9665, 0.9383, 0.9850], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8799, 0.9671, 0.9386, 0.9852], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8805, 0.9677, 0.9389, 0.9855], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8811, 0.9683, 0.9391, 0.9857], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8817, 0.9688, 0.9394, 0.9860], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8822, 0.9694, 0.9397, 0.9862], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8828, 0.9699, 0.9400, 0.9864], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8833, 0.9704, 0.9402, 0.9867], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8838, 0.9709, 0.9405, 0.9869], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8843, 0.9714, 0.9407, 0.9871], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8848, 0.9719, 0.9410, 0.9873], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8853, 0.9724, 0.9412, 0.9875], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8858, 0.9728, 0.9414, 0.9877], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8863, 0.9732, 0.9417, 0.9879], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8867, 0.9737, 0.9419, 0.9881], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8871, 0.9741, 0.9421, 0.9882], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8876, 0.9745, 0.9423, 0.9884], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8880, 0.9749, 0.9425, 0.9886], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8884, 0.9752, 0.9427, 0.9887], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8888, 0.9756, 0.9429, 0.9889], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8892, 0.9760, 0.9431, 0.9891], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8896, 0.9763, 0.9433, 0.9892], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8900, 0.9767, 0.9435, 0.9894], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8904, 0.9770, 0.9437, 0.9895], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8907, 0.9773, 0.9439, 0.9897], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8911, 0.9776, 0.9440, 0.9898], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8915, 0.9780, 0.9442, 0.9899], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8918, 0.9783, 0.9444, 0.9901], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8921, 0.9785, 0.9445, 0.9902], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8925, 0.9788, 0.9447, 0.9903], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8928, 0.9791, 0.9449, 0.9904], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8931, 0.9794, 0.9450, 0.9906], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8935, 0.9797, 0.9452, 0.9907], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8938, 0.9799, 0.9454, 0.9908], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8941, 0.9802, 0.9455, 0.9909], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8944, 0.9804, 0.9457, 0.9910], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8947, 0.9807, 0.9458, 0.9911], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8950, 0.9809, 0.9460, 0.9912], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8953, 0.9812, 0.9461, 0.9913], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8956, 0.9814, 0.9462, 0.9914], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8958, 0.9816, 0.9464, 0.9915], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8961, 0.9818, 0.9465, 0.9916], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8964, 0.9820, 0.9467, 0.9917], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8967, 0.9823, 0.9468, 0.9918], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8969, 0.9825, 0.9469, 0.9919], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8972, 0.9827, 0.9471, 0.9920], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8975, 0.9829, 0.9472, 0.9921], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8977, 0.9831, 0.9473, 0.9922], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8980, 0.9833, 0.9474, 0.9923], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8982, 0.9834, 0.9476, 0.9924], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8985, 0.9836, 0.9477, 0.9925], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8987, 0.9838, 0.9478, 0.9925], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8990, 0.9840, 0.9479, 0.9926], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8992, 0.9842, 0.9481, 0.9927], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8994, 0.9843, 0.9482, 0.9928], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8997, 0.9845, 0.9483, 0.9928], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.8999, 0.9847, 0.9484, 0.9929], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9001, 0.9848, 0.9485, 0.9930], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9003, 0.9850, 0.9486, 0.9931], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9006, 0.9851, 0.9487, 0.9931], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9008, 0.9853, 0.9488, 0.9932], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9010, 0.9855, 0.9490, 0.9933], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9012, 0.9856, 0.9491, 0.9933], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9014, 0.9857, 0.9492, 0.9934], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9016, 0.9859, 0.9493, 0.9935], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9018, 0.9860, 0.9494, 0.9935], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9020, 0.9862, 0.9495, 0.9936], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9022, 0.9863, 0.9496, 0.9937], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9024, 0.9864, 0.9497, 0.9937], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9026, 0.9866, 0.9498, 0.9938], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9028, 0.9867, 0.9499, 0.9938], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9030, 0.9868, 0.9500, 0.9939], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9032, 0.9870, 0.9501, 0.9939], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9034, 0.9871, 0.9502, 0.9940], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9036, 0.9872, 0.9503, 0.9941], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9038, 0.9873, 0.9504, 0.9941], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9040, 0.9874, 0.9505, 0.9942], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9041, 0.9876, 0.9505, 0.9942], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9043, 0.9877, 0.9506, 0.9943], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9045, 0.9878, 0.9507, 0.9943], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9047, 0.9879, 0.9508, 0.9944], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9048, 0.9880, 0.9509, 0.9944], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9050, 0.9881, 0.9510, 0.9945], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9052, 0.9882, 0.9511, 0.9945], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9054, 0.9883, 0.9512, 0.9946], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9055, 0.9884, 0.9513, 0.9946], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9057, 0.9885, 0.9513, 0.9947], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9059, 0.9886, 0.9514, 0.9947], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9060, 0.9887, 0.9515, 0.9947], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9062, 0.9888, 0.9516, 0.9948], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9063, 0.9889, 0.9517, 0.9948], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9065, 0.9890, 0.9518, 0.9949], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9067, 0.9891, 0.9518, 0.9949], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9068, 0.9892, 0.9519, 0.9950], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9070, 0.9893, 0.9520, 0.9950], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9071, 0.9894, 0.9521, 0.9950], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9073, 0.9895, 0.9522, 0.9951], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9074, 0.9895, 0.9522, 0.9951], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9076, 0.9896, 0.9523, 0.9952], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9077, 0.9897, 0.9524, 0.9952], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9079, 0.9898, 0.9525, 0.9952], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9080, 0.9899, 0.9525, 0.9953], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9082, 0.9900, 0.9526, 0.9953], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9083, 0.9900, 0.9527, 0.9954], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9084, 0.9901, 0.9528, 0.9954], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9086, 0.9902, 0.9528, 0.9954], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9087, 0.9903, 0.9529, 0.9955], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9089, 0.9903, 0.9530, 0.9955], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9090, 0.9904, 0.9530, 0.9955], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9091, 0.9905, 0.9531, 0.9956], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9093, 0.9906, 0.9532, 0.9956], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9094, 0.9906, 0.9533, 0.9956], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9095, 0.9907, 0.9533, 0.9957], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9097, 0.9908, 0.9534, 0.9957], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9098, 0.9908, 0.9535, 0.9957], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9099, 0.9909, 0.9535, 0.9958], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9101, 0.9910, 0.9536, 0.9958], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9102, 0.9910, 0.9537, 0.9958], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9103, 0.9911, 0.9537, 0.9958], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9104, 0.9912, 0.9538, 0.9959], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9106, 0.9912, 0.9539, 0.9959], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9107, 0.9913, 0.9539, 0.9959], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9108, 0.9914, 0.9540, 0.9960], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9109, 0.9914, 0.9540, 0.9960], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9111, 0.9915, 0.9541, 0.9960], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9112, 0.9916, 0.9542, 0.9960], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9113, 0.9916, 0.9542, 0.9961], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9114, 0.9917, 0.9543, 0.9961], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9115, 0.9917, 0.9544, 0.9961], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9117, 0.9918, 0.9544, 0.9962], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9118, 0.9918, 0.9545, 0.9962], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9119, 0.9919, 0.9545, 0.9962], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9120, 0.9920, 0.9546, 0.9962], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9121, 0.9920, 0.9547, 0.9963], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9122, 0.9921, 0.9547, 0.9963], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9123, 0.9921, 0.9548, 0.9963], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9125, 0.9922, 0.9548, 0.9963], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9126, 0.9922, 0.9549, 0.9964], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9127, 0.9923, 0.9550, 0.9964], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9128, 0.9923, 0.9550, 0.9964], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9129, 0.9924, 0.9551, 0.9964], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9130, 0.9924, 0.9551, 0.9965], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9131, 0.9925, 0.9552, 0.9965], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9132, 0.9925, 0.9552, 0.9965], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9133, 0.9926, 0.9553, 0.9965], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9134, 0.9926, 0.9554, 0.9965], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9135, 0.9927, 0.9554, 0.9966], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9136, 0.9927, 0.9555, 0.9966], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9137, 0.9928, 0.9555, 0.9966], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9139, 0.9928, 0.9556, 0.9966], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9140, 0.9929, 0.9556, 0.9967], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9141, 0.9929, 0.9557, 0.9967], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9142, 0.9930, 0.9557, 0.9967], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9143, 0.9930, 0.9558, 0.9967], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9144, 0.9930, 0.9558, 0.9967], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9145, 0.9931, 0.9559, 0.9968], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9146, 0.9931, 0.9559, 0.9968], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9147, 0.9932, 0.9560, 0.9968], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9147, 0.9932, 0.9560, 0.9968], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9148, 0.9933, 0.9561, 0.9968], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9149, 0.9933, 0.9561, 0.9969], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9150, 0.9933, 0.9562, 0.9969], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9151, 0.9934, 0.9563, 0.9969], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9152, 0.9934, 0.9563, 0.9969], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9153, 0.9935, 0.9564, 0.9969], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9154, 0.9935, 0.9564, 0.9969], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9155, 0.9935, 0.9564, 0.9970], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9156, 0.9936, 0.9565, 0.9970], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9157, 0.9936, 0.9565, 0.9970], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9158, 0.9936, 0.9566, 0.9970], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9159, 0.9937, 0.9566, 0.9970], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9160, 0.9937, 0.9567, 0.9970], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9161, 0.9938, 0.9567, 0.9971], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9161, 0.9938, 0.9568, 0.9971], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9162, 0.9938, 0.9568, 0.9971], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9163, 0.9939, 0.9569, 0.9971], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9164, 0.9939, 0.9569, 0.9971], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9165, 0.9939, 0.9570, 0.9971], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9166, 0.9940, 0.9570, 0.9972], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9167, 0.9940, 0.9571, 0.9972], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9168, 0.9940, 0.9571, 0.9972], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9168, 0.9941, 0.9572, 0.9972], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9169, 0.9941, 0.9572, 0.9972], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9170, 0.9941, 0.9573, 0.9972], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9171, 0.9942, 0.9573, 0.9973], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9172, 0.9942, 0.9573, 0.9973], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9173, 0.9942, 0.9574, 0.9973], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9173, 0.9943, 0.9574, 0.9973], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9174, 0.9943, 0.9575, 0.9973], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9175, 0.9943, 0.9575, 0.9973], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9176, 0.9944, 0.9576, 0.9973], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9177, 0.9944, 0.9576, 0.9974], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9177, 0.9944, 0.9577, 0.9974], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9178, 0.9945, 0.9577, 0.9974], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9179, 0.9945, 0.9577, 0.9974], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9180, 0.9945, 0.9578, 0.9974], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9181, 0.9945, 0.9578, 0.9974], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9181, 0.9946, 0.9579, 0.9974], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9182, 0.9946, 0.9579, 0.9975], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9183, 0.9946, 0.9579, 0.9975], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9184, 0.9947, 0.9580, 0.9975], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9185, 0.9947, 0.9580, 0.9975], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9185, 0.9947, 0.9581, 0.9975], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9186, 0.9947, 0.9581, 0.9975], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9187, 0.9948, 0.9582, 0.9975], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9188, 0.9948, 0.9582, 0.9975], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9188, 0.9948, 0.9582, 0.9976], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9189, 0.9948, 0.9583, 0.9976], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9190, 0.9949, 0.9583, 0.9976], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9191, 0.9949, 0.9584, 0.9976], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9191, 0.9949, 0.9584, 0.9976], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9192, 0.9950, 0.9584, 0.9976], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9193, 0.9950, 0.9585, 0.9976], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9194, 0.9950, 0.9585, 0.9976], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9194, 0.9950, 0.9586, 0.9977], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9195, 0.9951, 0.9586, 0.9977], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9196, 0.9951, 0.9586, 0.9977], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9196, 0.9951, 0.9587, 0.9977], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9197, 0.9951, 0.9587, 0.9977], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9198, 0.9951, 0.9588, 0.9977], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9199, 0.9952, 0.9588, 0.9977], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9199, 0.9952, 0.9588, 0.9977], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9200, 0.9952, 0.9589, 0.9977], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9201, 0.9952, 0.9589, 0.9978], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9201, 0.9953, 0.9589, 0.9978], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9202, 0.9953, 0.9590, 0.9978], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9203, 0.9953, 0.9590, 0.9978], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9203, 0.9953, 0.9591, 0.9978], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9204, 0.9954, 0.9591, 0.9978], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9205, 0.9954, 0.9591, 0.9978], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9205, 0.9954, 0.9592, 0.9978], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9206, 0.9954, 0.9592, 0.9978], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9207, 0.9954, 0.9592, 0.9979], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9207, 0.9955, 0.9593, 0.9979], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9208, 0.9955, 0.9593, 0.9979], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9209, 0.9955, 0.9594, 0.9979], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9209, 0.9955, 0.9594, 0.9979], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9210, 0.9956, 0.9594, 0.9979], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9211, 0.9956, 0.9595, 0.9979], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9211, 0.9956, 0.9595, 0.9979], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9212, 0.9956, 0.9595, 0.9979], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9213, 0.9956, 0.9596, 0.9979], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9213, 0.9957, 0.9596, 0.9979], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9214, 0.9957, 0.9596, 0.9980], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9215, 0.9957, 0.9597, 0.9980], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9215, 0.9957, 0.9597, 0.9980], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9216, 0.9957, 0.9597, 0.9980], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9216, 0.9958, 0.9598, 0.9980], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9217, 0.9958, 0.9598, 0.9980], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9218, 0.9958, 0.9598, 0.9980], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9218, 0.9958, 0.9599, 0.9980], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9219, 0.9958, 0.9599, 0.9980], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9219, 0.9958, 0.9599, 0.9980], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9220, 0.9959, 0.9600, 0.9980], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9221, 0.9959, 0.9600, 0.9981], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9221, 0.9959, 0.9601, 0.9981], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9222, 0.9959, 0.9601, 0.9981], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9223, 0.9959, 0.9601, 0.9981], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9223, 0.9960, 0.9602, 0.9981], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9224, 0.9960, 0.9602, 0.9981], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9224, 0.9960, 0.9602, 0.9981], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9225, 0.9960, 0.9603, 0.9981], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9225, 0.9960, 0.9603, 0.9981], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9226, 0.9960, 0.9603, 0.9981], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9227, 0.9961, 0.9603, 0.9981], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9227, 0.9961, 0.9604, 0.9981], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9228, 0.9961, 0.9604, 0.9982], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9228, 0.9961, 0.9604, 0.9982], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9229, 0.9961, 0.9605, 0.9982], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9230, 0.9961, 0.9605, 0.9982], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9230, 0.9962, 0.9605, 0.9982], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9231, 0.9962, 0.9606, 0.9982], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9231, 0.9962, 0.9606, 0.9982], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9232, 0.9962, 0.9606, 0.9982], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9232, 0.9962, 0.9607, 0.9982], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9233, 0.9962, 0.9607, 0.9982], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9234, 0.9963, 0.9607, 0.9982], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9234, 0.9963, 0.9608, 0.9982], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9235, 0.9963, 0.9608, 0.9982], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9235, 0.9963, 0.9608, 0.9983], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9236, 0.9963, 0.9609, 0.9983], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9236, 0.9963, 0.9609, 0.9983], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9237, 0.9964, 0.9609, 0.9983], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9237, 0.9964, 0.9610, 0.9983], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9238, 0.9964, 0.9610, 0.9983], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9238, 0.9964, 0.9610, 0.9983], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9239, 0.9964, 0.9610, 0.9983], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9240, 0.9964, 0.9611, 0.9983], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9240, 0.9964, 0.9611, 0.9983], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9241, 0.9965, 0.9611, 0.9983], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9241, 0.9965, 0.9612, 0.9983], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9242, 0.9965, 0.9612, 0.9983], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9242, 0.9965, 0.9612, 0.9983], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9243, 0.9965, 0.9613, 0.9984], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9243, 0.9965, 0.9613, 0.9984], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9244, 0.9965, 0.9613, 0.9984], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9244, 0.9966, 0.9613, 0.9984], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9245, 0.9966, 0.9614, 0.9984], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9245, 0.9966, 0.9614, 0.9984], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9246, 0.9966, 0.9614, 0.9984], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9246, 0.9966, 0.9615, 0.9984], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9247, 0.9966, 0.9615, 0.9984], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9247, 0.9966, 0.9615, 0.9984], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9248, 0.9966, 0.9615, 0.9984], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9248, 0.9967, 0.9616, 0.9984], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9249, 0.9967, 0.9616, 0.9984], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9249, 0.9967, 0.9616, 0.9984], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9250, 0.9967, 0.9617, 0.9984], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9250, 0.9967, 0.9617, 0.9984], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9251, 0.9967, 0.9617, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9251, 0.9967, 0.9617, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9252, 0.9967, 0.9618, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9252, 0.9968, 0.9618, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9253, 0.9968, 0.9618, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9253, 0.9968, 0.9619, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9254, 0.9968, 0.9619, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9254, 0.9968, 0.9619, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9255, 0.9968, 0.9619, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9255, 0.9968, 0.9620, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9256, 0.9968, 0.9620, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9256, 0.9969, 0.9620, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9257, 0.9969, 0.9621, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9257, 0.9969, 0.9621, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9258, 0.9969, 0.9621, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9258, 0.9969, 0.9621, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9259, 0.9969, 0.9622, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9259, 0.9969, 0.9622, 0.9985], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9260, 0.9969, 0.9622, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9260, 0.9970, 0.9622, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9261, 0.9970, 0.9623, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9261, 0.9970, 0.9623, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9261, 0.9970, 0.9623, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9262, 0.9970, 0.9624, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9262, 0.9970, 0.9624, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9263, 0.9970, 0.9624, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9263, 0.9970, 0.9624, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9264, 0.9970, 0.9625, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9264, 0.9970, 0.9625, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9265, 0.9971, 0.9625, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9265, 0.9971, 0.9625, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9266, 0.9971, 0.9626, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9266, 0.9971, 0.9626, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9266, 0.9971, 0.9626, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9267, 0.9971, 0.9626, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9267, 0.9971, 0.9627, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9268, 0.9971, 0.9627, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9268, 0.9971, 0.9627, 0.9986], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9269, 0.9972, 0.9627, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9269, 0.9972, 0.9628, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9270, 0.9972, 0.9628, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9270, 0.9972, 0.9628, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9270, 0.9972, 0.9628, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9271, 0.9972, 0.9629, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9271, 0.9972, 0.9629, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9272, 0.9972, 0.9629, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9272, 0.9972, 0.9629, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9273, 0.9972, 0.9630, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9273, 0.9973, 0.9630, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9273, 0.9973, 0.9630, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9274, 0.9973, 0.9630, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9274, 0.9973, 0.9631, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9275, 0.9973, 0.9631, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9275, 0.9973, 0.9631, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9276, 0.9973, 0.9631, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9276, 0.9973, 0.9632, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9276, 0.9973, 0.9632, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9277, 0.9973, 0.9632, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9277, 0.9973, 0.9632, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9278, 0.9974, 0.9633, 0.9987], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9278, 0.9974, 0.9633, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9279, 0.9974, 0.9633, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9279, 0.9974, 0.9633, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9279, 0.9974, 0.9634, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9280, 0.9974, 0.9634, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9280, 0.9974, 0.9634, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9281, 0.9974, 0.9634, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9281, 0.9974, 0.9635, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9281, 0.9974, 0.9635, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9282, 0.9974, 0.9635, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9282, 0.9974, 0.9635, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9283, 0.9975, 0.9636, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9283, 0.9975, 0.9636, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9283, 0.9975, 0.9636, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9284, 0.9975, 0.9636, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9284, 0.9975, 0.9637, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9285, 0.9975, 0.9637, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9285, 0.9975, 0.9637, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9285, 0.9975, 0.9637, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9286, 0.9975, 0.9637, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9286, 0.9975, 0.9638, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9287, 0.9975, 0.9638, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9287, 0.9975, 0.9638, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9287, 0.9976, 0.9638, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9288, 0.9976, 0.9639, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9288, 0.9976, 0.9639, 0.9988], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9288, 0.9976, 0.9639, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9289, 0.9976, 0.9639, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9289, 0.9976, 0.9640, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9290, 0.9976, 0.9640, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9290, 0.9976, 0.9640, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9290, 0.9976, 0.9640, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9291, 0.9976, 0.9640, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9291, 0.9976, 0.9641, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9292, 0.9976, 0.9641, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9292, 0.9976, 0.9641, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9292, 0.9977, 0.9641, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9293, 0.9977, 0.9642, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9293, 0.9977, 0.9642, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9293, 0.9977, 0.9642, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9294, 0.9977, 0.9642, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9294, 0.9977, 0.9642, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9295, 0.9977, 0.9643, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9295, 0.9977, 0.9643, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9295, 0.9977, 0.9643, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9296, 0.9977, 0.9643, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9296, 0.9977, 0.9644, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9296, 0.9977, 0.9644, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9297, 0.9977, 0.9644, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9297, 0.9977, 0.9644, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9297, 0.9978, 0.9644, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9298, 0.9978, 0.9645, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9298, 0.9978, 0.9645, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9299, 0.9978, 0.9645, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9299, 0.9978, 0.9645, 0.9989], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9299, 0.9978, 0.9646, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9300, 0.9978, 0.9646, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9300, 0.9978, 0.9646, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9300, 0.9978, 0.9646, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9301, 0.9978, 0.9646, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9301, 0.9978, 0.9647, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9301, 0.9978, 0.9647, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9302, 0.9978, 0.9647, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9302, 0.9978, 0.9647, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9302, 0.9978, 0.9647, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9303, 0.9979, 0.9648, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9303, 0.9979, 0.9648, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9304, 0.9979, 0.9648, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9304, 0.9979, 0.9648, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9304, 0.9979, 0.9649, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9305, 0.9979, 0.9649, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9305, 0.9979, 0.9649, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9305, 0.9979, 0.9649, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9306, 0.9979, 0.9649, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9306, 0.9979, 0.9650, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9306, 0.9979, 0.9650, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9307, 0.9979, 0.9650, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9307, 0.9979, 0.9650, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9307, 0.9979, 0.9650, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9308, 0.9979, 0.9651, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9308, 0.9979, 0.9651, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9308, 0.9980, 0.9651, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9309, 0.9980, 0.9651, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9309, 0.9980, 0.9651, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9309, 0.9980, 0.9652, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9310, 0.9980, 0.9652, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9310, 0.9980, 0.9652, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9310, 0.9980, 0.9652, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9311, 0.9980, 0.9652, 0.9990], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9311, 0.9980, 0.9653, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9311, 0.9980, 0.9653, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9312, 0.9980, 0.9653, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9312, 0.9980, 0.9653, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9312, 0.9980, 0.9653, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9313, 0.9980, 0.9654, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9313, 0.9980, 0.9654, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9313, 0.9980, 0.9654, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9314, 0.9980, 0.9654, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9314, 0.9980, 0.9654, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9314, 0.9981, 0.9655, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9315, 0.9981, 0.9655, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9315, 0.9981, 0.9655, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9315, 0.9981, 0.9655, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9316, 0.9981, 0.9655, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9316, 0.9981, 0.9656, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9316, 0.9981, 0.9656, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9317, 0.9981, 0.9656, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9317, 0.9981, 0.9656, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9317, 0.9981, 0.9656, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9318, 0.9981, 0.9657, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9318, 0.9981, 0.9657, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9318, 0.9981, 0.9657, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9318, 0.9981, 0.9657, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9319, 0.9981, 0.9657, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9319, 0.9981, 0.9658, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9319, 0.9981, 0.9658, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9320, 0.9981, 0.9658, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9320, 0.9981, 0.9658, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9320, 0.9982, 0.9658, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9321, 0.9982, 0.9659, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9321, 0.9982, 0.9659, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9321, 0.9982, 0.9659, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9322, 0.9982, 0.9659, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9322, 0.9982, 0.9659, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9322, 0.9982, 0.9660, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9323, 0.9982, 0.9660, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9323, 0.9982, 0.9660, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9323, 0.9982, 0.9660, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9323, 0.9982, 0.9660, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9324, 0.9982, 0.9660, 0.9991], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9324, 0.9982, 0.9661, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9324, 0.9982, 0.9661, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9325, 0.9982, 0.9661, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9325, 0.9982, 0.9661, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9325, 0.9982, 0.9661, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9326, 0.9982, 0.9662, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9326, 0.9982, 0.9662, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9326, 0.9982, 0.9662, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9326, 0.9982, 0.9662, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9327, 0.9983, 0.9662, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9327, 0.9983, 0.9663, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9327, 0.9983, 0.9663, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9328, 0.9983, 0.9663, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9328, 0.9983, 0.9663, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9328, 0.9983, 0.9663, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9329, 0.9983, 0.9663, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9329, 0.9983, 0.9664, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9329, 0.9983, 0.9664, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9329, 0.9983, 0.9664, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9330, 0.9983, 0.9664, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9330, 0.9983, 0.9664, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9330, 0.9983, 0.9665, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9331, 0.9983, 0.9665, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9331, 0.9983, 0.9665, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9331, 0.9983, 0.9665, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9331, 0.9983, 0.9665, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9332, 0.9983, 0.9666, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9332, 0.9983, 0.9666, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9332, 0.9983, 0.9666, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9333, 0.9983, 0.9666, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9333, 0.9983, 0.9666, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9333, 0.9984, 0.9666, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9334, 0.9984, 0.9667, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9334, 0.9984, 0.9667, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9334, 0.9984, 0.9667, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9334, 0.9984, 0.9667, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9335, 0.9984, 0.9667, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9335, 0.9984, 0.9667, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9335, 0.9984, 0.9668, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9336, 0.9984, 0.9668, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9336, 0.9984, 0.9668, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9336, 0.9984, 0.9668, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9336, 0.9984, 0.9668, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9337, 0.9984, 0.9669, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9337, 0.9984, 0.9669, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9337, 0.9984, 0.9669, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9337, 0.9984, 0.9669, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9338, 0.9984, 0.9669, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9338, 0.9984, 0.9669, 0.9992], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9338, 0.9984, 0.9670, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9339, 0.9984, 0.9670, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9339, 0.9984, 0.9670, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9339, 0.9984, 0.9670, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9339, 0.9984, 0.9670, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9340, 0.9984, 0.9670, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9340, 0.9984, 0.9671, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9340, 0.9985, 0.9671, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9341, 0.9985, 0.9671, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9341, 0.9985, 0.9671, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9341, 0.9985, 0.9671, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9341, 0.9985, 0.9672, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9342, 0.9985, 0.9672, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9342, 0.9985, 0.9672, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9342, 0.9985, 0.9672, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9342, 0.9985, 0.9672, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9343, 0.9985, 0.9672, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9343, 0.9985, 0.9673, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9343, 0.9985, 0.9673, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9343, 0.9985, 0.9673, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9344, 0.9985, 0.9673, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9344, 0.9985, 0.9673, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9344, 0.9985, 0.9673, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9345, 0.9985, 0.9674, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9345, 0.9985, 0.9674, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9345, 0.9985, 0.9674, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9345, 0.9985, 0.9674, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9346, 0.9985, 0.9674, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9346, 0.9985, 0.9674, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9346, 0.9985, 0.9675, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9346, 0.9985, 0.9675, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9347, 0.9985, 0.9675, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9347, 0.9985, 0.9675, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9347, 0.9985, 0.9675, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9347, 0.9985, 0.9675, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9348, 0.9986, 0.9676, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9348, 0.9986, 0.9676, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9348, 0.9986, 0.9676, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9349, 0.9986, 0.9676, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9349, 0.9986, 0.9676, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9349, 0.9986, 0.9676, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9349, 0.9986, 0.9677, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9350, 0.9986, 0.9677, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9350, 0.9986, 0.9677, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9350, 0.9986, 0.9677, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9350, 0.9986, 0.9677, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9351, 0.9986, 0.9677, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9351, 0.9986, 0.9678, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9351, 0.9986, 0.9678, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9351, 0.9986, 0.9678, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9352, 0.9986, 0.9678, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9352, 0.9986, 0.9678, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9352, 0.9986, 0.9678, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9352, 0.9986, 0.9679, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9353, 0.9986, 0.9679, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9353, 0.9986, 0.9679, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9353, 0.9986, 0.9679, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9353, 0.9986, 0.9679, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9354, 0.9986, 0.9679, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9354, 0.9986, 0.9680, 0.9993], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9354, 0.9986, 0.9680, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9354, 0.9986, 0.9680, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9355, 0.9986, 0.9680, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9355, 0.9986, 0.9680, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9355, 0.9986, 0.9680, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9355, 0.9986, 0.9681, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9356, 0.9987, 0.9681, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9356, 0.9987, 0.9681, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9356, 0.9987, 0.9681, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9356, 0.9987, 0.9681, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9357, 0.9987, 0.9681, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9357, 0.9987, 0.9682, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9357, 0.9987, 0.9682, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9357, 0.9987, 0.9682, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9358, 0.9987, 0.9682, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9358, 0.9987, 0.9682, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9358, 0.9987, 0.9682, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9358, 0.9987, 0.9682, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9359, 0.9987, 0.9683, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9359, 0.9987, 0.9683, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9359, 0.9987, 0.9683, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9359, 0.9987, 0.9683, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9360, 0.9987, 0.9683, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9360, 0.9987, 0.9683, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9360, 0.9987, 0.9684, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9360, 0.9987, 0.9684, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9361, 0.9987, 0.9684, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9361, 0.9987, 0.9684, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9361, 0.9987, 0.9684, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9361, 0.9987, 0.9684, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9361, 0.9987, 0.9685, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9362, 0.9987, 0.9685, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9362, 0.9987, 0.9685, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9362, 0.9987, 0.9685, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9362, 0.9987, 0.9685, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9363, 0.9987, 0.9685, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9363, 0.9987, 0.9685, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9363, 0.9987, 0.9686, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9363, 0.9987, 0.9686, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9364, 0.9987, 0.9686, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9364, 0.9987, 0.9686, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9364, 0.9988, 0.9686, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9364, 0.9988, 0.9686, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9365, 0.9988, 0.9687, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9365, 0.9988, 0.9687, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9365, 0.9988, 0.9687, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9365, 0.9988, 0.9687, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9366, 0.9988, 0.9687, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9366, 0.9988, 0.9687, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9366, 0.9988, 0.9687, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9366, 0.9988, 0.9688, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9366, 0.9988, 0.9688, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9367, 0.9988, 0.9688, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9367, 0.9988, 0.9688, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9367, 0.9988, 0.9688, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9367, 0.9988, 0.9688, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9368, 0.9988, 0.9689, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9368, 0.9988, 0.9689, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9368, 0.9988, 0.9689, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9368, 0.9988, 0.9689, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9369, 0.9988, 0.9689, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9369, 0.9988, 0.9689, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9369, 0.9988, 0.9689, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9369, 0.9988, 0.9690, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9369, 0.9988, 0.9690, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9370, 0.9988, 0.9690, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9370, 0.9988, 0.9690, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9370, 0.9988, 0.9690, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9370, 0.9988, 0.9690, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9371, 0.9988, 0.9691, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9371, 0.9988, 0.9691, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9371, 0.9988, 0.9691, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9371, 0.9988, 0.9691, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9371, 0.9988, 0.9691, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9372, 0.9988, 0.9691, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9372, 0.9988, 0.9691, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9372, 0.9988, 0.9692, 0.9994], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9372, 0.9988, 0.9692, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9373, 0.9988, 0.9692, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9373, 0.9988, 0.9692, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9373, 0.9989, 0.9692, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9373, 0.9989, 0.9692, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9373, 0.9989, 0.9692, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9374, 0.9989, 0.9693, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9374, 0.9989, 0.9693, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9374, 0.9989, 0.9693, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9374, 0.9989, 0.9693, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9375, 0.9989, 0.9693, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9375, 0.9989, 0.9693, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9375, 0.9989, 0.9693, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9375, 0.9989, 0.9694, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9375, 0.9989, 0.9694, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9376, 0.9989, 0.9694, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9376, 0.9989, 0.9694, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9376, 0.9989, 0.9694, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9376, 0.9989, 0.9694, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9377, 0.9989, 0.9694, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9377, 0.9989, 0.9695, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9377, 0.9989, 0.9695, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9377, 0.9989, 0.9695, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9377, 0.9989, 0.9695, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9378, 0.9989, 0.9695, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9378, 0.9989, 0.9695, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9378, 0.9989, 0.9696, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9378, 0.9989, 0.9696, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9379, 0.9989, 0.9696, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9379, 0.9989, 0.9696, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9379, 0.9989, 0.9696, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9379, 0.9989, 0.9696, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9379, 0.9989, 0.9696, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9380, 0.9989, 0.9697, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9380, 0.9989, 0.9697, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9380, 0.9989, 0.9697, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9380, 0.9989, 0.9697, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9380, 0.9989, 0.9697, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9381, 0.9989, 0.9697, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9381, 0.9989, 0.9697, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9381, 0.9989, 0.9698, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9381, 0.9989, 0.9698, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9382, 0.9989, 0.9698, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9382, 0.9989, 0.9698, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9382, 0.9989, 0.9698, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9382, 0.9989, 0.9698, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9382, 0.9989, 0.9698, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9383, 0.9989, 0.9699, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9383, 0.9990, 0.9699, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9383, 0.9990, 0.9699, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9383, 0.9990, 0.9699, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9383, 0.9990, 0.9699, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9384, 0.9990, 0.9699, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9384, 0.9990, 0.9699, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9384, 0.9990, 0.9700, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9384, 0.9990, 0.9700, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9384, 0.9990, 0.9700, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9385, 0.9990, 0.9700, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9385, 0.9990, 0.9700, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9385, 0.9990, 0.9700, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9385, 0.9990, 0.9700, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9386, 0.9990, 0.9700, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9386, 0.9990, 0.9701, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9386, 0.9990, 0.9701, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9386, 0.9990, 0.9701, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9386, 0.9990, 0.9701, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9387, 0.9990, 0.9701, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9387, 0.9990, 0.9701, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9387, 0.9990, 0.9701, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9387, 0.9990, 0.9702, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9387, 0.9990, 0.9702, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9388, 0.9990, 0.9702, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9388, 0.9990, 0.9702, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9388, 0.9990, 0.9702, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9388, 0.9990, 0.9702, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9388, 0.9990, 0.9702, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9389, 0.9990, 0.9703, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9389, 0.9990, 0.9703, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9389, 0.9990, 0.9703, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9389, 0.9990, 0.9703, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9389, 0.9990, 0.9703, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9390, 0.9990, 0.9703, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9390, 0.9990, 0.9703, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9390, 0.9990, 0.9704, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9390, 0.9990, 0.9704, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9390, 0.9990, 0.9704, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9391, 0.9990, 0.9704, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9391, 0.9990, 0.9704, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9391, 0.9990, 0.9704, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9391, 0.9990, 0.9704, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9391, 0.9990, 0.9704, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9392, 0.9990, 0.9705, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9392, 0.9990, 0.9705, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9392, 0.9990, 0.9705, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9392, 0.9990, 0.9705, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9392, 0.9990, 0.9705, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9393, 0.9990, 0.9705, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9393, 0.9990, 0.9705, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9393, 0.9990, 0.9706, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9393, 0.9990, 0.9706, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9393, 0.9990, 0.9706, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9394, 0.9991, 0.9706, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9394, 0.9991, 0.9706, 0.9995], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9394, 0.9991, 0.9706, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9394, 0.9991, 0.9706, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9394, 0.9991, 0.9707, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9395, 0.9991, 0.9707, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9395, 0.9991, 0.9707, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9395, 0.9991, 0.9707, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9395, 0.9991, 0.9707, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9395, 0.9991, 0.9707, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9396, 0.9991, 0.9707, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9396, 0.9991, 0.9707, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9396, 0.9991, 0.9708, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9396, 0.9991, 0.9708, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9396, 0.9991, 0.9708, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9397, 0.9991, 0.9708, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9397, 0.9991, 0.9708, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9397, 0.9991, 0.9708, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9397, 0.9991, 0.9708, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9397, 0.9991, 0.9709, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9398, 0.9991, 0.9709, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9398, 0.9991, 0.9709, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9398, 0.9991, 0.9709, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9398, 0.9991, 0.9709, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9398, 0.9991, 0.9709, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9398, 0.9991, 0.9709, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9399, 0.9991, 0.9709, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9399, 0.9991, 0.9710, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9399, 0.9991, 0.9710, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9399, 0.9991, 0.9710, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9399, 0.9991, 0.9710, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9400, 0.9991, 0.9710, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9400, 0.9991, 0.9710, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9400, 0.9991, 0.9710, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9400, 0.9991, 0.9710, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9400, 0.9991, 0.9711, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9401, 0.9991, 0.9711, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9401, 0.9991, 0.9711, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9401, 0.9991, 0.9711, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9401, 0.9991, 0.9711, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9401, 0.9991, 0.9711, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9402, 0.9991, 0.9711, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9402, 0.9991, 0.9712, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9402, 0.9991, 0.9712, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9402, 0.9991, 0.9712, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9402, 0.9991, 0.9712, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9402, 0.9991, 0.9712, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9403, 0.9991, 0.9712, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9403, 0.9991, 0.9712, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9403, 0.9991, 0.9712, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9403, 0.9991, 0.9713, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9403, 0.9991, 0.9713, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9404, 0.9991, 0.9713, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9404, 0.9991, 0.9713, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9404, 0.9991, 0.9713, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9404, 0.9991, 0.9713, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9404, 0.9991, 0.9713, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9405, 0.9991, 0.9713, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9405, 0.9991, 0.9714, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9405, 0.9991, 0.9714, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9405, 0.9991, 0.9714, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9405, 0.9991, 0.9714, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9405, 0.9992, 0.9714, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9406, 0.9992, 0.9714, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9406, 0.9992, 0.9714, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9406, 0.9992, 0.9715, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9406, 0.9992, 0.9715, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9406, 0.9992, 0.9715, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9407, 0.9992, 0.9715, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9407, 0.9992, 0.9715, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9407, 0.9992, 0.9715, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9407, 0.9992, 0.9715, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9407, 0.9992, 0.9715, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9407, 0.9992, 0.9716, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9408, 0.9992, 0.9716, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9408, 0.9992, 0.9716, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9408, 0.9992, 0.9716, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9408, 0.9992, 0.9716, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9408, 0.9992, 0.9716, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9409, 0.9992, 0.9716, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9409, 0.9992, 0.9716, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9409, 0.9992, 0.9717, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9409, 0.9992, 0.9717, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9409, 0.9992, 0.9717, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9409, 0.9992, 0.9717, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9410, 0.9992, 0.9717, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9410, 0.9992, 0.9717, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9410, 0.9992, 0.9717, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9410, 0.9992, 0.9717, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9410, 0.9992, 0.9718, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9411, 0.9992, 0.9718, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9411, 0.9992, 0.9718, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9411, 0.9992, 0.9718, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9411, 0.9992, 0.9718, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9411, 0.9992, 0.9718, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9411, 0.9992, 0.9718, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9412, 0.9992, 0.9718, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9412, 0.9992, 0.9719, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9412, 0.9992, 0.9719, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9412, 0.9992, 0.9719, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9412, 0.9992, 0.9719, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9413, 0.9992, 0.9719, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9413, 0.9992, 0.9719, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9413, 0.9992, 0.9719, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9413, 0.9992, 0.9719, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9413, 0.9992, 0.9720, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9413, 0.9992, 0.9720, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9414, 0.9992, 0.9720, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9414, 0.9992, 0.9720, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9414, 0.9992, 0.9720, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9414, 0.9992, 0.9720, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9414, 0.9992, 0.9720, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9414, 0.9992, 0.9720, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9415, 0.9992, 0.9721, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9415, 0.9992, 0.9721, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9415, 0.9992, 0.9721, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9415, 0.9992, 0.9721, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9415, 0.9992, 0.9721, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9416, 0.9992, 0.9721, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9416, 0.9992, 0.9721, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9416, 0.9992, 0.9721, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9416, 0.9992, 0.9722, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9416, 0.9992, 0.9722, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9416, 0.9992, 0.9722, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9417, 0.9992, 0.9722, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9417, 0.9992, 0.9722, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9417, 0.9992, 0.9722, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9417, 0.9992, 0.9722, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9417, 0.9992, 0.9722, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9417, 0.9992, 0.9722, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9418, 0.9992, 0.9723, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9418, 0.9992, 0.9723, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9418, 0.9992, 0.9723, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9418, 0.9992, 0.9723, 0.9996], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.9418, 0.9992, 0.9723, 0.9996], grad_fn=<SigmoidBackward0>)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage['policy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9418, 0.9992, 0.9723, 0.9996], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage['policy'][-1]\n",
    "plt.plot(storage['policy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
